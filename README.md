# Crawling_Python

<br>

> 검색 엔진의 근간이 되는 웹 크롤러는 인터넷상에 존재하는 웹 문서들을 추적하여 필요한 정보를 수집하는 기술.

__고성능 웹크롤러 시스템을 구현하기 위해 필요한 내용__
- 웹에 대한 최신 정보를 제공받기 위해 다운로드 성능을 높이는 속도 문제
- 재다운로드를 막도록 하는 유일성 문제
- 과거에 받은 문서가 아직도 유효한지, 혹은 변해서 없어졌는 지 알아내는 현행화 문제
- 크롤러 배제 표준과 저작권 문제

[https://lyb1495.tistory.com/17](https://lyb1495.tistory.com/17)

<br>

> seed URL을 주면 관련 URL을 찾아내고, 그 URL들에서 또 다른 하이퍼링크를 찾아내고 계속해서 이과정을 반복하며 하이퍼링크들을 다운로드 하는 프로그램.

[https://velog.io/@mowinckel/%EC%9B%B9-%ED%81%AC%EB%A1%A4%EB%A7%81-I](https://velog.io/@mowinckel/%EC%9B%B9-%ED%81%AC%EB%A1%A4%EB%A7%81-I)
[https://www.microsoft.com/en-us/research/wp-content/uploads/2009/09/EDS-WebCrawlerArchitecture.pdf](https://www.microsoft.com/en-us/research/wp-content/uploads/2009/09/EDS-WebCrawlerArchitecture.pdf)

<br>

> 웹크롤러는 조직적, 자동화된 방법으로 월드 와이드 웹을 탐색하는 컴퓨터 프로그램으로 웹크롤러가 하는 작업을 웹 크롤링 혹은 스파이더링 이라고 부름.

[https://ko.wikipedia.org/wiki/%EC%9B%B9_%ED%81%AC%EB%A1%A4%EB%9F%AC](https://ko.wikipedia.org/wiki/%EC%9B%B9_%ED%81%AC%EB%A1%A4%EB%9F%AC)


